import os
import xml.etree.ElementTree as ET
from tqdm import tqdm

import pandas as pd

def parse_risk_section_from_all_xml(
    doc_id,
    extract_dir="data/extracted_reports",
    save_dir="data/parsed_sections",
    log_path="logs/risk_extract_errors.txt"
):
    """
    è§£å‡æ¸ˆã¿XBRLãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€Œäº‹æ¥­ç­‰ã®ãƒªã‚¹ã‚¯ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    æˆåŠŸã™ã‚Œã° .txt ã«ä¿å­˜ã€‚å¤±æ•—ãƒ­ã‚°ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ã®ã¿è¨˜éŒ²ã€‚
    """
    os.makedirs(save_dir, exist_ok=True)
    os.makedirs(os.path.dirname(log_path), exist_ok=True)  # â† ã“ã‚ŒãŒé‡è¦ï¼

    xbrl_dir = os.path.join(extract_dir, doc_id)
    if not os.path.exists(xbrl_dir):
        with open(log_path, "a") as f:
            f.write(f"[{doc_id}] è§£å‡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xbrl_dir}\n")
        return None

    ns = {"jpcrp": "http://disclosure.edinet-fsa.go.jp/taxonomy/jpcrp/2023-01-01"}
    candidate_tags = ["BusinessRisks", "BusinessRisk"]

    xml_files = []
    for root, _, files in os.walk(xbrl_dir):
        for file in files:
            if file.endswith(".xbrl") and "jpcrp" in file:
                xml_files.append(os.path.join(root, file))

    for path in tqdm(xml_files, desc=f"ğŸ” {doc_id} å†…XMLæ¢ç´¢", ncols=100, leave=False):
        try:
            tree = ET.parse(path)
            root_el = tree.getroot()
            for tag in candidate_tags:
                el = root_el.find(f".//jpcrp:{tag}", ns)
                if el is not None and el.text:
                    out_path = os.path.join(save_dir, f"{doc_id}.txt")
                    with open(out_path, "w", encoding="utf-8") as f:
                        f.write(el.text.strip())
                    return el.text.strip()
        except Exception as e:
            with open(log_path, "a") as f:
                f.write(f"[{doc_id}] XML parse error: {path} - {e}\n")

    with open(log_path, "a") as f:
        f.write(f"[{doc_id}] ãƒªã‚¹ã‚¯æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n")

    return None


def extract_risk_from_all_csvs(
    extract_dir="data/extracted_reports",
    save_dir="data/parsed_sections_csv",
    log_path="logs/risk_extract_errors.txt"
):
    """
    è§£å‡æ¸ˆã¿ã® XBRL_TO_CSV ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã€Œäº‹æ¥­ç­‰ã®ãƒªã‚¹ã‚¯ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã—ã€CSVã§ä¿å­˜ã€‚
    """
    os.makedirs(save_dir, exist_ok=True)
    os.makedirs(os.path.dirname(log_path), exist_ok=True)

    doc_ids = sorted(os.listdir(extract_dir))
    success, skipped, failed = 0, 0, 0

    for doc_id in tqdm(doc_ids, desc="ğŸ§  Extracting Risk CSVs", ncols=100):
        out_path = os.path.join(save_dir, f"{doc_id}.csv")
        if os.path.exists(out_path):
            skipped += 1
            continue

        xbrl_csv_dir = os.path.join(extract_dir, doc_id, "XBRL_TO_CSV")
        if not os.path.exists(xbrl_csv_dir):
            failed += 1
            with open(log_path, "a") as f:
                f.write(f"[{doc_id}] âŒ XBRL_TO_CSV ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n")
            continue

        csv_files = [f for f in os.listdir(xbrl_csv_dir) if f.startswith("jpcrp") and f.endswith(".csv")]
        if not csv_files:
            failed += 1
            with open(log_path, "a") as f:
                f.write(f"[{doc_id}] âŒ jpcrp*.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n")
            continue

        try:
            path = os.path.join(xbrl_csv_dir, csv_files[0])
            df = pd.read_csv(path, encoding="utf-16", sep="\t")
            risk_df = df[df["é …ç›®å"].str.contains("äº‹æ¥­ç­‰ã®ãƒªã‚¹ã‚¯", na=False)]

            if not risk_df.empty:
                risk_df.to_csv(out_path, index=False)
                success += 1
            else:
                failed += 1
                with open(log_path, "a") as f:
                    f.write(f"[{doc_id}] âš ï¸ ãƒªã‚¹ã‚¯é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n")
        except Exception as e:
            failed += 1
            with open(log_path, "a") as f:
                f.write(f"[{doc_id}] âš ï¸ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\n")

    print(f"\nâœ… å®Œäº†: {success} ä»¶æŠ½å‡º, {skipped} ä»¶ã‚¹ã‚­ãƒƒãƒ—, {failed} ä»¶å¤±æ•—")